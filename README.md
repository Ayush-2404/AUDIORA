# ğŸ¶ AUDIORA: Music Recognition Application  
_Shazam-like Audio Identification Tool_

## ğŸ“Œ Introduction

**AUDIORA** is an advanced music recognition system designed to identify songs from short audio clips. Inspired by platforms like **Shazam**, it leverages cutting-edge **audio fingerprinting**, **real-time processing**, and a full-stack web interface to bridge the gap between user experience and embedded audio recognition technology.

Built with a modern **React frontend**, a powerful **Go-based backend**, and a **Python audio engine**, AUDIORA provides a scalable and responsive solution for music lovers and developers alike.

## ğŸ§  Project Overview

AUDIORA converts recorded audio into unique fingerprints, matches them against a fingerprint database, and returns the matching song metadata to the user â€” all through a user-friendly web interface. It supports live recordings, precise fingerprinting, and fast identification optimized for cloud-scale deployment.

## âœ¨ Features

- ğŸ¤ **Real-time audio capture from browser**
- ğŸ¼ **Audio fingerprinting using FFT-based frequency analysis**
- ğŸ” **Accurate song matching via Locality-Sensitive Hashing (LSH)**
- ğŸ§© Modular backend in **Go + Python**
- ğŸŒ Modern, responsive frontend using **React** and **Tailwind CSS**
- ğŸ§ª Basic testing using Postman, MongoDB Compass, and logs
- â˜ï¸ Scalable and containerized using **Docker**

## ğŸ§° Technologies Used

| ![React](https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB) | ![Tailwind CSS](https://img.shields.io/badge/Tailwind_CSS-38B2AC?style=for-the-badge&logo=tailwind-css&logoColor=white) | ![Go](https://img.shields.io/badge/Go-00ADD8?style=for-the-badge&logo=go&logoColor=white) | ![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white) |
|---|---|---|---|
| ![Flask](https://img.shields.io/badge/Flask-000000?style=for-the-badge&logo=flask&logoColor=white) | ![Librosa](https://img.shields.io/badge/Librosa-9E9E9E?style=for-the-badge&logo=python&logoColor=white) | ![MongoDB](https://img.shields.io/badge/MongoDB-4EA94B?style=for-the-badge&logo=mongodb&logoColor=white) | ![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white) |

| Layer            | Tools & Languages |
|------------------|-------------------|
| **Frontend**     | React.js, Tailwind CSS, Web Audio API |
| **Backend (API)**| Golang (Go), Flask (Python bridge) |
| **Audio Engine** | Python, Librosa, NumPy, SciPy, FFmpeg |
| **Database**     | MongoDB |
| **Containerization** | Docker |
| **Testing Tools** | Postman, MongoDB Compass |

## ğŸ“ Project Structure

```text
AUDIORA/
â”œâ”€â”€ Backend/
â”‚ â”œâ”€â”€ audio_engine/           # Python audio fingerprinting logic
â”‚ â”œâ”€â”€ app.go                  # Go server API
â”‚ â””â”€â”€ flask_bridge.py         # Bridge to Python engine
â”œâ”€â”€ Frontend/
â”‚ â”œâ”€â”€ src/                    # React components
â”‚ â””â”€â”€ index.html
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ database/                 # MongoDB fingerprint collections
â”œâ”€â”€ tests/                    # Postman/API tests
â””â”€â”€ README.md
```

## ğŸ› ï¸ Recognition Workflow

1. **Record**: User records audio via browser.
2. **Preprocess**: Audio cleaned, converted to mono WAV using FFmpeg.
3. **Fingerprinting**: Spectral peaks extracted using FFT; hashes generated.
4. **Match**: Fingerprints matched against MongoDB using LSH.
5. **Result**: Matching song displayed with title, artist, and album.

## ğŸš€ How to Run

### ğŸ“¥ Clone Repo

  ```bash
    git clone https://github.com/rakshitnarang018/Audiora01
    cd Audiora01
  ```

### ğŸ§  Backend Setup

1. Set up Python environment:

  ```bash
    python -m venv .venv
    source .venv/bin/activate      # On Linux/Mac
    .venv\Scripts\activate         # On Windows
  ```

2. Install Python dependencies:

  ```bash
    pip install -r requirements.txt
  ```

3. Run the Flask backend:

  ```bash
    cd Backend
    python app.py
  ```
Flask server will run at: http://localhost:5000

### ğŸ¨ Frontend Setup
You can either run the frontend with npm or use Docker Compose:
  ```bash
    cd Frontend
    npm install
    npm run dev
  ```
Visit http://localhost:3000 in your browser to use the app.

### ğŸ³ Docker Deployment
AUDIORA uses Docker Compose to containerize and serve the React frontend, while the backend is run manually on your local machine.

#### ğŸ“ Prerequisites
- Docker & Docker Compose installed: Get Docker

#### ğŸš€ Build and Start the Frontend

From the root of your project (where docker-compose.yml is present or create it as shown below):

  ```bash
    docker-compose up --build
  ```

##  ğŸ§ª Testing
Basic testing was performed using:

- âœ… Postman â€“ for API request testing
- âœ… MongoDB Compass â€“ to inspect stored fingerprints
- âœ… Temporary audio logs â€“ for audio integrity validation
- âœ… Manual logs â€“ to verify backend/frontend flow

## ğŸ–¼ï¸ UI Snapshots
- ğŸ§ Landing Page â€“ â€œWelcome to AUDIORAâ€
- ğŸŸ¢ Recording Animation â€“ â€œListening for your tune...â€
- ğŸ“Š Analyzing Page â€“ â€œMatching your music...â€
- ğŸ‰ Result Page â€“ Displays identified song details

## ğŸ”­ Future Enhancements
- ğŸ” Live-stream music detection
- ğŸŒ Multilingual/global music database
- âš¡ Edge computing for ultra-low latency
- ğŸ”’ Audio encryption and user profile sync
- ğŸ¤– AI-based music genre or mood tagging

## ğŸ“š Acknowledgments
- Librosa, SciPy, FFmpeg, Flask, MongoDB
- Shazam â€“ for inspiring the concept
- React + Tailwind community
- Python and Go open-source ecosystems